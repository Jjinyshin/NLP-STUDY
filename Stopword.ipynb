{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 영어 문장에서 NLTK가 정의한 영어 불용어를 제거하는 실습을 하고\n",
    "- 한국어 문장에서 직접 정의한 불용어를 제거해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수:  179\n",
      "불용어 20개 출력:  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "stop_words_list = stopwords.words('english')\n",
    "print('불용어 개수: ', len(stop_words_list))\n",
    "print('불용어 20개 출력: ', stop_words_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 : ['The', 'sun', 'dipped', 'below', 'the', 'horizon', ',', 'casting', 'a', 'warm', 'glow', 'across', 'the', 'tranquil', 'meadow', '.', 'The', 'aroma', 'of', 'freshly', 'baked', 'bread', 'wafted', 'through', 'the', 'air', ',', 'enticing', 'everyone', 'in', 'the', 'vicinity', '.', 'Lost', 'in', 'thought', ',', 'she', 'wandered', 'through', 'the', 'bustling', 'city', 'streets', ',', 'absorbing', 'the', 'vibrant', 'energy', 'around', 'her', '.']\n",
      "불용어 제거 후 : ['The', 'sun', 'dipped', 'horizon', ',', 'casting', 'warm', 'glow', 'across', 'tranquil', 'meadow', '.', 'The', 'aroma', 'freshly', 'baked', 'bread', 'wafted', 'air', ',', 'enticing', 'everyone', 'vicinity', '.', 'Lost', 'thought', ',', 'wandered', 'bustling', 'city', 'streets', ',', 'absorbing', 'vibrant', 'energy', 'around', '.']\n"
     ]
    }
   ],
   "source": [
    "# nltk이용해서 불용어 제거해보기\n",
    "example = \"The sun dipped below the horizon, casting a warm glow across the tranquil meadow. The aroma of freshly baked bread wafted through the air, enticing everyone in the vicinity. Lost in thought, she wandered through the bustling city streets, absorbing the vibrant energy around her.\"\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_tokens = word_tokenize(example)\n",
    "\n",
    "result = []\n",
    "for word in word_tokens: \n",
    "    if word not in stop_words: \n",
    "        result.append(word) \n",
    "\n",
    "print('불용어 제거 전 :',word_tokens) \n",
    "print('불용어 제거 후 :',result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 직접 불용어를 정의해보고, 예시 문장에서 사용자가 정의한 불용어 사전으로부터 불용어를 제거해 보자.\n",
    "- 아래의 불용어는 임의로 선정한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  불용어 제거 전 : ['최근', '다이어트', '보조', '제', '리뷰', '데이터', '모아줘']\n",
      "0  불용어 제거 후 : ['최근', '다이어트', '보조', '제', '리뷰', '데이터', '모아줘']\n",
      "\n",
      "1  불용어 제거 전 : ['한', '달', '간', '조회', '수가', '높은', '지진', '관련', '기사', '찾아줘']\n",
      "1  불용어 제거 후 : ['한', '달', '조회', '수가', '높은', '지진', '기사', '찾아줘']\n",
      "\n",
      "2  불용어 제거 전 : ['6', '개', '월간', '블랙', '핑크', '관련', '영상', '찾아줘']\n",
      "2  불용어 제거 후 : ['6', '개', '월간', '블랙', '핑크', '영상', '찾아줘']\n",
      "\n",
      "3  불용어 제거 전 : ['1년', '간', '밀리', '의', '서재', '후기', '모아줘']\n",
      "3  불용어 제거 후 : ['1년', '밀리', '의', '서재', '후기', '모아줘']\n",
      "\n",
      "4  불용어 제거 전 : ['1년', '간', '올라온', '맛집', '게시', '글', '모아줘']\n",
      "4  불용어 제거 후 : ['1년', '올라온', '맛집', '게시', '글', '모아줘']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "\n",
    "# 배열로 바꿔보자\n",
    "examples = [\"최근 다이어트 보조제 리뷰 데이터 모아줘\", \"한 달간 조회수가 높은 지진 관련 기사 찾아줘\", \"6개월간 블랙핑크 관련 영상 찾아줘\", \"1년간 밀리의 서재 후기 모아줘\", \"1년간 올라온 맛집 게시글 모아줘\"]\n",
    "\n",
    "stop_words = \"간 관련\"\n",
    "stop_words = set(stop_words.split(' '))\n",
    "\n",
    "word_tokens = []\n",
    "results = []\n",
    "# okt\n",
    "for example in examples:\n",
    "  word_token = okt.morphs(example)\n",
    "  word_tokens.append(word_token)\n",
    "  result = [word for word in word_token if not word in stop_words]\n",
    "  results.append(result)\n",
    "\n",
    "for i in range(len(word_tokens)):\n",
    "  print(i, ' 불용어 제거 전 :',word_tokens[i]) \n",
    "  print(i, ' 불용어 제거 후 :',results[i])\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  불용어 제거 전 : ['최근', '다이어트', '보조제', '리뷰', '데이터', '모으', '아', '주', '어']\n",
      "0  불용어 제거 후 : ['최근', '다이어트', '보조제', '리뷰', '모으', '아', '주', '어']\n",
      "\n",
      "1  불용어 제거 전 : ['한', '달', '간', '조회', '수가', '높', '은', '지진', '관련', '기사', '찾', '아', '주', '어']\n",
      "1  불용어 제거 후 : ['한', '달', '조회', '수가', '높', '은', '지진', '기사', '찾', '아', '주', '어']\n",
      "\n",
      "2  불용어 제거 전 : ['6', '개월', '간', '블랙', '핑크', '관련', '영상', '찾', '아', '주', '어']\n",
      "2  불용어 제거 후 : ['6', '개월', '블랙', '핑크', '영상', '찾', '아', '주', '어']\n",
      "\n",
      "3  불용어 제거 전 : ['1', '년', '간', '밀', '리', '의', '서재', '후기', '모으', '아', '주', '어']\n",
      "3  불용어 제거 후 : ['1', '년', '밀', '리', '의', '서재', '후기', '모으', '아', '주', '어']\n",
      "\n",
      "4  불용어 제거 전 : ['1', '년', '간', '올라오', 'ㄴ', '맛', '집', '게시', '글', '모으', '아', '주', '어']\n",
      "4  불용어 제거 후 : ['1', '년', '올라오', 'ㄴ', '맛', '집', '게시', '글', '모으', '아', '주', '어']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "kkma = Kkma()\n",
    "\n",
    "examples = [\"최근 다이어트 보조제 리뷰 데이터 모아줘\", \"한 달간 조회수가 높은 지진 관련 기사 찾아줘\", \"6개월간 블랙핑크 관련 영상 찾아줘\", \"1년간 밀리의 서재 후기 모아줘\", \"1년간 올라온 맛집 게시글 모아줘\"]\n",
    "\n",
    "stop_words = \"간 관련 데이터 가 \"\n",
    "stop_words = set(stop_words.split(' '))\n",
    "\n",
    "word_tokens = []\n",
    "results = []\n",
    "# okt\n",
    "for example in examples:\n",
    "  word_token = kkma.morphs(example)\n",
    "  word_tokens.append(word_token)\n",
    "  result = [word for word in word_token if not word in stop_words]\n",
    "  results.append(result)\n",
    "\n",
    "for i in range(len(word_tokens)):\n",
    "  print(i, ' 불용어 제거 전 :',word_tokens[i]) \n",
    "  print(i, ' 불용어 제거 후 :',results[i])\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
